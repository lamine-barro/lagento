#!/usr/bin/env python3
"""
Script de classification des opportunitÃ©s fusionnÃ©es
Tri par type d'institution puis par type d'opportunitÃ©
"""

import pandas as pd
import os
from datetime import datetime

class ClassifierOpportunites:
    def __init__(self, data_dir="/Users/laminebarro/agent-O/data"):
        self.data_dir = data_dir
        self.input_file = "Opportunites_Fusionnees.csv"
        self.output_file = "Opportunites_Classees.csv"
        
        # Ordre de prioritÃ© pour les types d'institutions
        self.institution_order = [
            'MINISTERE_AGENCE',
            'BANQUE_DEVELOPPEMENT', 
            'FONDS_INVESTISSEMENT',
            'INCUBATEUR_ACCELERATEUR',
            'CENTRE_FORMATION',
            'ORGANISATION_INTERNATIONALE',
            'ASSOCIATION_ENTREPRENEURIALE',
            'HUB_INNOVATION',
            'MICROFINANCE',
            'ESPACE_COWORKING',
            'GUICHET_UNIQUE',
            'AGENCE_PROMOTION',
            'COOPERATION_DIASPORA',
            'FEDERATION_PUBLIQUE'
        ]
        
        # Ordre de prioritÃ© pour les types d'opportunitÃ©s
        self.opportunity_order = [
            'FINANCEMENT',
            'INCUBATION',
            'ACCELERATION',
            'FORMATION',
            'CONCOURS',
            'STAGE',
            'EVENEMENT',
            'ASSISTANCE_TECHNIQUE',
            'SUBVENTION/FINANCEMENT',
            'FINANCEMENT/RECHERCHE',
            'FINANCEMENT/ACCELERATION',
            'INFRASTRUCTURE/FINANCEMENT',
            'INCUBATION/FORMATION',
            'FORMATION/ACCELERATION'
        ]
    
    def load_data(self):
        """Charge les donnÃ©es fusionnÃ©es"""
        file_path = os.path.join(self.data_dir, self.input_file)
        return pd.read_csv(file_path)
    
    def create_sorting_keys(self, df):
        """CrÃ©e des clÃ©s de tri numÃ©riques"""
        print("ğŸ”„ CrÃ©ation des clÃ©s de tri...")
        
        # CrÃ©er un mapping pour les types d'institutions
        institution_map = {inst: i for i, inst in enumerate(self.institution_order)}
        # Ajouter des valeurs pour les institutions non prÃ©vues
        max_inst_order = len(self.institution_order)
        
        # CrÃ©er un mapping pour les types d'opportunitÃ©s
        opportunity_map = {opp: i for i, opp in enumerate(self.opportunity_order)}
        max_opp_order = len(self.opportunity_order)
        
        # Appliquer les clÃ©s de tri
        df['institution_sort_key'] = df['institution_type'].map(
            lambda x: institution_map.get(x, max_inst_order)
        )
        
        df['opportunity_sort_key'] = df['type'].map(
            lambda x: opportunity_map.get(x, max_opp_order)
        )
        
        return df
    
    def sort_data(self, df):
        """Trie les donnÃ©es selon les critÃ¨res dÃ©finis"""
        print("ğŸ“Š Tri des donnÃ©es...")
        
        # Tri principal : institution_type, puis type d'opportunitÃ©, puis titre
        df_sorted = df.sort_values([
            'institution_sort_key',
            'opportunity_sort_key', 
            'institution',
            'titre'
        ]).reset_index(drop=True)
        
        # Supprimer les colonnes de tri temporaires
        df_sorted = df_sorted.drop(['institution_sort_key', 'opportunity_sort_key'], axis=1)
        
        return df_sorted
    
    def generate_classification_stats(self, df_sorted):
        """GÃ©nÃ¨re des statistiques sur la classification"""
        stats = {}
        
        print("\nğŸ“ˆ STATISTIQUES DE CLASSIFICATION")
        print("="*50)
        
        # Grouper par type d'institution
        by_institution = df_sorted.groupby('institution_type').size().reindex(
            self.institution_order, fill_value=0
        )
        
        print("\nğŸ¢ RÃ‰PARTITION PAR TYPE D'INSTITUTION:")
        total = len(df_sorted)
        cumul = 0
        for inst_type, count in by_institution.items():
            if count > 0:
                pct = count/total*100
                cumul += count
                print(f"  {inst_type}: {count} opportunitÃ©s ({pct:.1f}%) - Cumul: {cumul}")
        
        # Grouper par type d'opportunitÃ©  
        by_opportunity = df_sorted.groupby('type').size().reindex(
            self.opportunity_order, fill_value=0
        )
        
        print("\nğŸ¯ RÃ‰PARTITION PAR TYPE D'OPPORTUNITÃ‰:")
        cumul = 0
        for opp_type, count in by_opportunity.items():
            if count > 0:
                pct = count/total*100
                cumul += count
                print(f"  {opp_type}: {count} opportunitÃ©s ({pct:.1f}%) - Cumul: {cumul}")
        
        # Matrice croisÃ©e
        print("\nğŸ“Š MATRICE CROISÃ‰E (TOP 5 de chaque):")
        cross_tab = pd.crosstab(df_sorted['institution_type'], df_sorted['type'])
        
        # Afficher seulement les combinaisons non nulles les plus importantes
        top_institutions = by_institution.head(5).index
        top_opportunities = by_opportunity.head(5).index
        
        cross_subset = cross_tab.loc[top_institutions, top_opportunities]
        print(cross_subset.to_string())
        
        stats = {
            'by_institution': by_institution.to_dict(),
            'by_opportunity': by_opportunity.to_dict(),
            'cross_tab': cross_tab.to_dict()
        }
        
        return stats
    
    def save_classified_data(self, df_sorted):
        """Sauvegarde les donnÃ©es classÃ©es"""
        output_path = os.path.join(self.data_dir, self.output_file)
        df_sorted.to_csv(output_path, index=False, encoding='utf-8')
        print(f"\nğŸ’¾ DonnÃ©es classÃ©es sauvegardÃ©es: {output_path}")
        return output_path
    
    def generate_report(self, stats, total_records):
        """GÃ©nÃ¨re un rapport de classification"""
        report = f"""
=== RAPPORT DE CLASSIFICATION DES OPPORTUNITÃ‰S ===
Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ğŸ“Š RÃ‰SUMÃ‰:
- Total d'opportunitÃ©s classÃ©es: {total_records}
- CritÃ¨re de tri principal: Type d'institution
- CritÃ¨re de tri secondaire: Type d'opportunitÃ©
- CritÃ¨re de tri tertiaire: Institution puis titre

ğŸ¢ HIÃ‰RARCHIE DES INSTITUTIONS (ordre de prioritÃ©):
"""
        for i, inst_type in enumerate(self.institution_order, 1):
            count = stats['by_institution'].get(inst_type, 0)
            if count > 0:
                report += f"{i:2d}. {inst_type}: {count} opportunitÃ©s\n"
        
        report += f"""
ğŸ¯ HIÃ‰RARCHIE DES OPPORTUNITÃ‰S (ordre de prioritÃ©):
"""
        for i, opp_type in enumerate(self.opportunity_order, 1):
            count = stats['by_opportunity'].get(opp_type, 0)
            if count > 0:
                report += f"{i:2d}. {opp_type}: {count} opportunitÃ©s\n"
        
        report += f"""
ğŸ“‹ LOGIQUE DE CLASSIFICATION:
1. PrioritÃ© aux institutions gouvernementales et financiÃ¨res
2. Ensuite les incubateurs et centres de formation
3. Puis les organisations internationales et associations
4. Enfin les structures spÃ©cialisÃ©es

5. Au sein de chaque type d'institution:
   - Financement en prioritÃ©
   - Puis incubation/accÃ©lÃ©ration
   - Ensuite formation
   - Enfin Ã©vÃ©nements et concours

ğŸ¯ AVANTAGES DE CETTE CLASSIFICATION:
- Facilite la recherche par type d'acteur
- Groupe les opportunitÃ©s similaires
- Optimise les recommandations de l'agent Lagento
- AmÃ©liore l'expÃ©rience utilisateur

ğŸ“ˆ PROCHAINES Ã‰TAPES:
- IntÃ©gration dans la base vectorielle
- Configuration des filtres de recherche
- Tests des recommandations personnalisÃ©es
        """
        
        return report
    
    def run_classification(self):
        """ExÃ©cute la classification complÃ¨te"""
        print("ğŸš€ DÃ‰MARRAGE DE LA CLASSIFICATION")
        print("="*50)
        
        try:
            # 1. Charger les donnÃ©es
            print("ğŸ“‚ Chargement des donnÃ©es fusionnÃ©es...")
            df = self.load_data()
            print(f"âœ… {len(df)} opportunitÃ©s chargÃ©es")
            
            # 2. CrÃ©er les clÃ©s de tri
            df_with_keys = self.create_sorting_keys(df)
            
            # 3. Trier les donnÃ©es
            df_sorted = self.sort_data(df_with_keys)
            
            # 4. GÃ©nÃ©rer les statistiques
            stats = self.generate_classification_stats(df_sorted)
            
            # 5. Sauvegarder
            output_path = self.save_classified_data(df_sorted)
            
            # 6. GÃ©nÃ©rer le rapport
            report = self.generate_report(stats, len(df_sorted))
            
            # Sauvegarder le rapport
            report_path = os.path.join(self.data_dir, "rapport_classification.txt")
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(report)
            
            print(f"ğŸ“‹ Rapport sauvegardÃ©: {report_path}")
            print(report)
            
            return {
                'success': True,
                'output_file': output_path,
                'report_file': report_path,
                'total_records': len(df_sorted),
                'stats': stats
            }
            
        except Exception as e:
            print(f"âŒ Erreur lors de la classification: {str(e)}")
            return {'success': False, 'error': str(e)}

if __name__ == "__main__":
    classifier = ClassifierOpportunites()
    result = classifier.run_classification()
    
    if result['success']:
        print(f"\nâœ… Classification terminÃ©e avec succÃ¨s!")
        print(f"ğŸ“ Fichier classÃ©: {result['output_file']}")
        print(f"ğŸ“Š Rapport: {result['report_file']}")
        print(f"ğŸ“ˆ Total: {result['total_records']} opportunitÃ©s classÃ©es")
    else:
        print(f"âŒ Erreur: {result['error']}")