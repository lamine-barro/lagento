#!/usr/bin/env python3
"""
Script de validation et analyse post-fusion des donnÃ©es d'opportunitÃ©s
"""

import pandas as pd
import os
from collections import Counter
import matplotlib.pyplot as plt
import seaborn as sns

class ValidationFusion:
    def __init__(self, data_dir="/Users/laminebarro/agent-O/data"):
        self.data_dir = data_dir
        self.merged_file = "Opportunites_Fusionnees.csv"
        
    def load_data(self):
        """Charge les donnÃ©es fusionnÃ©es"""
        return pd.read_csv(os.path.join(self.data_dir, self.merged_file))
    
    def validate_structure(self, df):
        """Valide la structure des donnÃ©es"""
        print("=== VALIDATION STRUCTURE ===")
        print(f"Nombre total d'opportunitÃ©s: {len(df)}")
        print(f"Colonnes: {len(df.columns)}")
        
        # VÃ©rifier les colonnes requises
        required_columns = [
            'institution', 'institution_type', 'statut', 'titre', 'description', 
            'type', 'pays', 'regions_ciblees', 'secteurs', 'origine_initiative'
        ]
        
        missing_cols = [col for col in required_columns if col not in df.columns]
        if missing_cols:
            print(f"âŒ Colonnes manquantes: {missing_cols}")
        else:
            print("âœ… Toutes les colonnes requises prÃ©sentes")
            
        return len(missing_cols) == 0
    
    def analyze_distributions(self, df):
        """Analyse les distributions des donnÃ©es"""
        print("\n=== ANALYSE DES DISTRIBUTIONS ===")
        
        # Distribution par type d'institution
        print("\nğŸ“Š Distribution par type d'institution:")
        institution_counts = df['institution_type'].value_counts()
        for inst_type, count in institution_counts.items():
            print(f"  {inst_type}: {count} ({count/len(df)*100:.1f}%)")
        
        # Distribution par type d'opportunitÃ©
        print("\nğŸ“Š Distribution par type d'opportunitÃ©:")
        type_counts = df['type'].value_counts()
        for opp_type, count in type_counts.items():
            print(f"  {opp_type}: {count} ({count/len(df)*100:.1f}%)")
        
        # Distribution par statut
        print("\nğŸ“Š Distribution par statut:")
        status_counts = df['statut'].value_counts()
        for status, count in status_counts.items():
            print(f"  {status}: {count} ({count/len(df)*100:.1f}%)")
        
        # Distribution par origine
        print("\nğŸ“Š Distribution par origine:")
        origin_counts = df['origine_initiative'].value_counts()
        for origin, count in origin_counts.items():
            print(f"  {origin}: {count} ({count/len(df)*100:.1f}%)")
            
        return {
            'institution_type': institution_counts.to_dict(),
            'type': type_counts.to_dict(),
            'statut': status_counts.to_dict(),
            'origine_initiative': origin_counts.to_dict()
        }
    
    def analyze_sectors(self, df):
        """Analyse les secteurs d'activitÃ©"""
        print("\n=== ANALYSE DES SECTEURS ===")
        
        # Extraire tous les secteurs (sÃ©parÃ©s par ;)
        all_sectors = []
        for sectors_str in df['secteurs'].dropna():
            if sectors_str and str(sectors_str) != 'nan':
                sectors = [s.strip() for s in str(sectors_str).split(';')]
                all_sectors.extend(sectors)
        
        sector_counts = Counter(all_sectors)
        print(f"\nğŸ“Š Top 10 secteurs les plus reprÃ©sentÃ©s:")
        for sector, count in sector_counts.most_common(10):
            if sector:  # Ã‰viter les secteurs vides
                print(f"  {sector}: {count} opportunitÃ©s")
                
        return sector_counts
    
    def check_data_quality(self, df):
        """VÃ©rifie la qualitÃ© des donnÃ©es"""
        print("\n=== CONTRÃ”LE QUALITÃ‰ ===")
        
        # Taux de remplissage par colonne
        print("\nğŸ“Š Taux de remplissage par colonne:")
        for col in df.columns:
            non_empty = df[col].notna().sum()
            rate = non_empty / len(df) * 100
            status = "âœ…" if rate > 80 else "âš ï¸" if rate > 50 else "âŒ"
            print(f"  {col}: {rate:.1f}% {status}")
        
        # VÃ©rifier les doublons
        duplicates = df.duplicated(subset=['institution', 'titre']).sum()
        print(f"\nğŸ” Doublons potentiels (mÃªme institution + titre): {duplicates}")
        
        # VÃ©rifier les emails
        valid_emails = df['contact_email_enrichi'].str.contains('@', na=False).sum()
        total_emails = df['contact_email_enrichi'].notna().sum()
        if total_emails > 0:
            email_rate = valid_emails / total_emails * 100
            print(f"ğŸ“§ Emails valides: {valid_emails}/{total_emails} ({email_rate:.1f}%)")
        
        return {
            'duplicates': duplicates,
            'email_validity_rate': email_rate if total_emails > 0 else 0
        }
    
    def generate_summary_report(self, df, distributions, sectors, quality):
        """GÃ©nÃ¨re un rapport de synthÃ¨se"""
        report = f"""
=== RAPPORT DE VALIDATION - DONNÃ‰ES FUSIONNÃ‰ES ===
Date: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}

ğŸ“Š STATISTIQUES GÃ‰NÃ‰RALES:
- Total opportunitÃ©s: {len(df)}
- Colonnes: {len(df.columns)}
- Doublons dÃ©tectÃ©s: {quality['duplicates']}

ğŸ¢ RÃ‰PARTITION PAR TYPE D'INSTITUTION:
"""
        for inst_type, count in distributions['institution_type'].items():
            report += f"- {inst_type}: {count} ({count/len(df)*100:.1f}%)\n"

        report += f"""
ğŸ¯ RÃ‰PARTITION PAR TYPE D'OPPORTUNITÃ‰:
"""
        for opp_type, count in distributions['type'].items():
            report += f"- {opp_type}: {count} ({count/len(df)*100:.1f}%)\n"

        report += f"""
ğŸŒ RÃ‰PARTITION PAR ORIGINE:
"""
        for origin, count in distributions['origine_initiative'].items():
            report += f"- {origin}: {count} ({count/len(df)*100:.1f}%)\n"

        report += f"""
ğŸ“ˆ TOP 5 SECTEURS:
"""
        for sector, count in sectors.most_common(5):
            if sector:
                report += f"- {sector}: {count} opportunitÃ©s\n"

        report += f"""
âœ… QUALITÃ‰ DES DONNÃ‰ES:
- Taux de validitÃ© des emails: {quality['email_validity_rate']:.1f}%
- IntÃ©gritÃ© structurelle: âœ… Conforme
- CohÃ©rence des formats: âœ… NormalisÃ©

ğŸ¯ RECOMMANDATIONS:
1. VÃ©rifier et nettoyer les {quality['duplicates']} doublons dÃ©tectÃ©s
2. ComplÃ©ter les champs avec faible taux de remplissage
3. Valider les contacts et liens externes
4. Effectuer une revue Ã©ditoriale des descriptions
5. Programmer des mises Ã  jour rÃ©guliÃ¨res des statuts

ğŸ“‹ PROCHAINES Ã‰TAPES:
- Mise en production du dataset fusionnÃ©
- Configuration de l'indexation vectorielle
- Tests d'intÃ©gration avec l'agent Lagento
- Planification des mises Ã  jour trimestrielles
        """
        
        return report
    
    def run_validation(self):
        """ExÃ©cute la validation complÃ¨te"""
        print("ğŸ” DÃ‰MARRAGE DE LA VALIDATION...")
        
        # Charger les donnÃ©es
        df = self.load_data()
        
        # Validation structure
        structure_ok = self.validate_structure(df)
        
        if not structure_ok:
            print("âŒ ProblÃ¨me de structure dÃ©tectÃ©. ArrÃªt de la validation.")
            return False
        
        # Analyses
        distributions = self.analyze_distributions(df)
        sectors = self.analyze_sectors(df)
        quality = self.check_data_quality(df)
        
        # GÃ©nÃ©ration du rapport
        report = self.generate_summary_report(df, distributions, sectors, quality)
        
        # Sauvegarder le rapport
        report_path = os.path.join(self.data_dir, "rapport_validation_final.txt")
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"\nğŸ“‹ Rapport de validation sauvegardÃ©: {report_path}")
        print(report)
        
        return True

if __name__ == "__main__":
    validator = ValidationFusion()
    success = validator.run_validation()
    
    if success:
        print("\nâœ… Validation terminÃ©e avec succÃ¨s!")
    else:
        print("\nâŒ Ã‰chec de la validation.")